{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d94352",
   "metadata": {},
   "source": [
    "# Numerical Analysis for Non-Linear Optimization | Module 2\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Monte Carlo methods and **random number generation** serve as a cornerstone in **non-linear optimization** and **scientific computing**. They approximate solutions to deterministic problems via random sampling, and they also appear in **finance**, **risk analysis**, and **machine learning**. This module covers:\n",
    "\n",
    "- **PRNGs vs. QRNs**, plus validation (Kolmogorov–Smirnov, histograms).  \n",
    "- **Monte Carlo** fundamentals (estimating $\\pi$, convergence).  \n",
    "- **Brownian motion**: A key stochastic process for advanced models.  \n",
    "- **Variance reduction** (antithetic variables, best samples).  \n",
    "- **Moment control** to match specific mean/variance/skewness.  \n",
    "- Applications to **financial modeling**: GBM, option pricing, VaR.\n",
    "\n",
    "---\n",
    "\n",
    "## Pseudo and Quasi-Random Number Generation\n",
    "\n",
    "### Pseudo-Random Numbers (PRNs)\n",
    "\n",
    "PRNs are deterministic but appear random:\n",
    "\n",
    "- Typically **seed-based** (e.g., Mersenne Twister).  \n",
    "- Standard for Monte Carlo simulations.\n",
    "\n",
    "### Quasi-Random Numbers (QRNs)\n",
    "\n",
    "Low-discrepancy sequences:\n",
    "\n",
    "- **Sobol**, **Halton**, etc.  \n",
    "- Provide **more uniform coverage**, often faster integration convergence.\n",
    "\n",
    "### Comparison: PRNs vs. QRNs\n",
    "\n",
    "| Feature       | PRNs (Pseudo-Random)          | QRNs (Quasi-Random)      |\n",
    "|---------------|-------------------------------|--------------------------|\n",
    "| Generation    | Seed-based algorithm          | Deterministic sequence   |\n",
    "| Periodicity   | Yes (can be extremely long)   | None                     |\n",
    "| Uniformity    | Moderate (by chance)          | High (low discrepancy)   |\n",
    "| Integration   | $\\sim 1/\\sqrt{N}$             | Potentially faster       |\n",
    "| Usage         | General Monte Carlo           | Integration, optimization|\n",
    "\n",
    "### Implementation Examples\n",
    "\n",
    "#### Using NumPy’s Modern PRNG API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1f2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "random_nums = rng.random(10)\n",
    "print(random_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56505b47",
   "metadata": {},
   "source": [
    "#### Generating Secure Random Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e39786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import secrets\n",
    "import string\n",
    "\n",
    "def generate_password(length=12):\n",
    "    chars = string.ascii_letters + string.digits + string.punctuation\n",
    "    return \"\".join(secrets.choice(chars) for _ in range(length))\n",
    "\n",
    "print(\"Secure Password:\", generate_password())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4d69f",
   "metadata": {},
   "source": [
    "#### Quasi-Random (Sobol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e6f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.qmc import Sobol\n",
    "\n",
    "sobol = Sobol(d=2, scramble=False)\n",
    "qrn_points = sobol.random(n=10)\n",
    "print(qrn_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14151c8",
   "metadata": {},
   "source": [
    "### Statistical Tests & Visualization\n",
    "\n",
    "- **Kolmogorov–Smirnov** test to check uniformity.  \n",
    "- **Histogram** + **KDE** for distribution checks.\n",
    "\n",
    "---\n",
    "\n",
    "## Monte Carlo Simulations: Fundamentals\n",
    "\n",
    "### Estimating $\\pi$ Using Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c90370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "import numpy as np\n",
    "\n",
    "@njit(parallel=True)\n",
    "def monte_carlo_pi(n):\n",
    "    count = 0\n",
    "    for i in prange(n):\n",
    "        x, y = np.random.random(), np.random.random()\n",
    "        if x**2 + y**2 <= 1:\n",
    "            count += 1\n",
    "    return 4.0 * count / n\n",
    "\n",
    "print(\"Monte Carlo Pi:\", monte_carlo_pi(1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ff0d6",
   "metadata": {},
   "source": [
    "### Monte Carlo Convergence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_values = np.logspace(2, 6, num=20, dtype=int)\n",
    "estimates = [monte_carlo_pi(n) for n in n_values]\n",
    "\n",
    "plt.plot(n_values, estimates, marker='o', linestyle='--')\n",
    "plt.xscale('log')\n",
    "plt.axhline(y=$\\pi$, color='red', linestyle='dashed', label=\"$\\pi$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04b645",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Brownian Motion\n",
    "\n",
    "### Definition & Properties\n",
    "\n",
    "A **standard Brownian motion** $W_t$:\n",
    "\n",
    "1. $W_0=0$.  \n",
    "2. Independent, stationary increments.  \n",
    "3. $\\mathbb{E}[W_t]=0$, $\\mathrm{Var}(W_t)=t$.  \n",
    "4. Continuous, nowhere differentiable paths.\n",
    "\n",
    "### Mathematical Characteristics\n",
    "\n",
    "- **Covariance**: $\\text{Cov}(W_s, W_t)=\\min(s,t)$.  \n",
    "- **Markov** & **martingale** properties.  \n",
    "- **Scaling**: $W_{ct}\\overset{d}{=}\\sqrt{c}W_t$.\n",
    "\n",
    "### Simulation of Brownian Motion in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "T, N = 1.0, 1000\n",
    "dt = T / N\n",
    "n_paths = 5\n",
    "time = np.linspace(0, T, N+1)\n",
    "\n",
    "np.random.seed(42)\n",
    "W = np.zeros((n_paths, N+1))\n",
    "for i in range(n_paths):\n",
    "    increments = np.random.normal(0, np.sqrt(dt), size=N)\n",
    "    W[i, 1:] = np.cumsum(increments)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for i in range(n_paths):\n",
    "    plt.plot(time, W[i], label=f\"Path {i+1}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f32e21",
   "metadata": {},
   "source": [
    "### Variants & Applications\n",
    "\n",
    "- **Geometric Brownian Motion (GBM)** in finance.  \n",
    "- **Fractional Brownian Motion**.  \n",
    "- **Brownian Bridge**.\n",
    "\n",
    "---\n",
    "\n",
    "## Variance Reduction Techniques\n",
    "\n",
    "### Best Samples\n",
    "\n",
    "- **Importance Sampling**: Weighted sampling in high-importance regions.  \n",
    "- **Stratified Sampling**: Partition domain.  \n",
    "- **Quasi-Random** (see Section 2.2).\n",
    "\n",
    "### Antithetic Variables\n",
    "\n",
    "#### Conceptual Overview & Code\n",
    "\n",
    "Example $\\pi$-estimator with antithetic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def estimate_pi_standard(n_samples=10000):\n",
    "    x = np.random.rand(n_samples)\n",
    "    y = np.random.rand(n_samples)\n",
    "    inside = (x**2 + y**2) <= 1\n",
    "    return 4 * np.mean(inside)\n",
    "\n",
    "def estimate_pi_antithetic(n_samples=10000):\n",
    "    half = n_samples // 2\n",
    "    x = np.random.rand(half)\n",
    "    y = np.random.rand(half)\n",
    "    x_anti = 1 - x\n",
    "    y_anti = 1 - y\n",
    "    inside = np.concatenate([\n",
    "        (x**2 + y**2) <= 1,\n",
    "        (x_anti**2 + y_anti**2) <= 1\n",
    "    ])\n",
    "    return 4 * np.mean(inside)\n",
    "\n",
    "print(\"Standard Monte Carlo:\", estimate_pi_standard(1000000))\n",
    "print(\"Antithetic Variates:\", estimate_pi_antithetic(1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f13282",
   "metadata": {},
   "source": [
    "#### Results & Comparison\n",
    "\n",
    "- Without antithetic: ~3.14156  \n",
    "- With antithetic: ~3.14159  \n",
    "\n",
    "---\n",
    "\n",
    "## Moment Control Techniques\n",
    "\n",
    "**Goal**: Ensure the simulated samples have desired **mean**, **variance**, or higher moments (e.g., skewness, kurtosis).  \n",
    "\n",
    "### Statistical Moments\n",
    "\n",
    "1. **Mean** $(\\mu)$  \n",
    "2. **Variance** $(\\sigma^2)$  \n",
    "3. **Skewness** $(\\gamma_1)$  \n",
    "4. **Kurtosis** $(\\gamma_2)$\n",
    "\n",
    "### Matching Mean and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8acb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_normal_samples(target_mean, target_std, size=1000):\n",
    "    samples = np.random.normal(0, 1, size)\n",
    "    adjusted_samples = (samples - np.mean(samples)) / np.std(samples)\n",
    "    adjusted_samples = target_mean + target_std * adjusted_samples\n",
    "    return adjusted_samples\n",
    "\n",
    "target_mean, target_std = 10, 2\n",
    "samples = generate_normal_samples(target_mean, target_std, 10000)\n",
    "print(\"Mean:\", np.mean(samples))\n",
    "print(\"Std Dev:\", np.std(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bdcaad",
   "metadata": {},
   "source": [
    "### Adjusting Higher-Order Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def adjust_higher_moments(samples, target_skew, target_kurt):\n",
    "    current_skew = skew(samples)\n",
    "    current_kurt = kurtosis(samples)\n",
    "    scaled = samples * (target_skew / (current_skew+1e-9))\n",
    "    shifted = scaled + (target_kurt - current_kurt)\n",
    "    return shifted\n",
    "\n",
    "target_skew, target_kurt = 1, 3\n",
    "samples = adjust_higher_moments(samples, target_skew, target_kurt)\n",
    "print(\"Skew:\", skew(samples))\n",
    "print(\"Kurtosis:\", kurtosis(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ba8ac",
   "metadata": {},
   "source": [
    "### Applications of Moment Control\n",
    "\n",
    "- **Monte Carlo**: Generate random variables matching real-world mean/variance.  \n",
    "- **Financial Modeling**: Match historical return skew, kurtosis.  \n",
    "- **Improved Realism**: Helps ensure simulations reflect actual data.\n",
    "\n",
    "---\n",
    "\n",
    "## Stochastic Modeling in Finance\n",
    "\n",
    "### Geometric Brownian Motion (GBM)\n",
    "\n",
    "#### GBM SDE & Closed-Form Solution\n",
    "\n",
    "$$\n",
    "dS_t = \\mu S_t\\,dt + \\sigma S_t\\,dW_t\n",
    "\\quad\\Longrightarrow\\quad\n",
    "S_t = S_0 e^{(\\mu-\\tfrac12\\sigma^2)t + \\sigma W_t}.\n",
    "$$\n",
    "\n",
    "#### Discretizing GBM (Exponential Form)\n",
    "\n",
    "$$\n",
    "S_{t+\\Delta t} = S_t \\exp\\Bigl((\\mu-\\tfrac12\\sigma^2)\\Delta t + \\sigma\\sqrt{\\Delta t}\\,Z\\Bigr).\n",
    "$$\n",
    "\n",
    "#### Euler–Maruyama for GBM\n",
    "\n",
    "$$\n",
    "S_{t+\\Delta t} \\approx S_t + \\mu S_t\\,\\Delta t + \\sigma S_t\\,\\Delta W_t.\n",
    "$$\n",
    "\n",
    "#### Extended GBM Example (simulate_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def simulate_gbm(S0, mu, sigma, T, N):\n",
    "    dt = T / N\n",
    "    t = np.linspace(0, T, N)\n",
    "    \n",
    "    W = np.cumsum(np.random.randn(N) * np.sqrt(dt))\n",
    "    S = S0 * np.exp((mu - 0.5*sigma^2)*t + sigma*W)\n",
    "    return t, S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6451a",
   "metadata": {},
   "source": [
    "### Monte Carlo for European Option Pricing\n",
    "\n",
    "A single-step approach under risk-neutral measure; compute average discounted payoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58059ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def monte_carlo_european_call(S0, K, T, r, sigma, num_sims):\n",
    "    dt = T\n",
    "    U = np.random.normal(0, 1, num_sims//2)\n",
    "    V = -U\n",
    "    Z = np.concatenate((U, V))\n",
    "\n",
    "    ST = S0 * np.exp((r - 0.5*sigma^2)*dt + sigma*np.sqrt(dt)*Z)\n",
    "    payoff = np.maximum(ST - K, 0)\n",
    "    discounted = np.exp(-r*T)*payoff\n",
    "    return np.mean(discounted), np.std(discounted)/np.sqrt(num_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c10e2d",
   "metadata": {},
   "source": [
    "### Value at Risk (VaR) Estimation via Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f64851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_var(initial_value, mu, sigma, T, alpha, num_sims):\n",
    "    Z = np.random.normal(0, 1, num_sims)\n",
    "    ST = initial_value * np.exp((mu - 0.5\\sigma^2)*T + sigma*np.sqrt(T)*Z)\n",
    "    losses = initial_value - ST\n",
    "    var_estimate = np.percentile(losses, 100 * alpha)\n",
    "    return var_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0035c721",
   "metadata": {},
   "source": [
    "### Advantages and Limitations of Monte Carlo in Finance\n",
    "\n",
    "- **Highly flexible** for exotic instruments.  \n",
    "- **Can incorporate** variance reduction, moment matching.  \n",
    "- Potentially **time-consuming** for high accuracy or path-dependent derivatives.  \n",
    "- **Model assumptions** (GBM, constant volatility) may deviate from reality.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "**Random number generation** (pseudo vs. quasi), **Monte Carlo fundamentals**, **variance reduction**, and **moment control** constitute a powerful toolkit for **numerical analysis** and **non-linear optimization**. Combined with knowledge of **Brownian motion** (and extensions like GBM), one can tackle **financial applications** (option pricing, VaR) and beyond. Ensuring correct **statistical moments** and employing **antithetic or quasi-random** sampling can significantly improve efficiency and realism.\n",
    "\n",
    "---\n",
    "\n",
    "## Consolidated Exercises\n",
    "\n",
    "- **Basic Random Number Generation**  \n",
    "  - Generate a $10\\times10$ array of uniform random numbers; compute mean & std.  \n",
    "  - Generate 20 random integers between 1 and 10; count frequencies.\n",
    "\n",
    "- **Pseudo & Quasi-Random Implementation**  \n",
    "  - Implement a **Linear Congruential Generator (LCG)** for 1000 samples; plot histogram.  \n",
    "  - Generate & compare **Halton** vs. **Sobol** sequences in 2D.\n",
    "\n",
    "- **Statistical Distributions & Tests**  \n",
    "  - Generate & plot exponential & binomial distributions.  \n",
    "  - Perform a KS test on a sample of normal random numbers.\n",
    "\n",
    "- **Monte Carlo Integration**  \n",
    "  - Implement a Monte Carlo estimator for $\\int_0^1 \\sin(x)\\,dx$. Compare vs. standard numerical integration.  \n",
    "  - Repeat with **quasi-random** sampling (Sobol/Halton). Compare convergence.\n",
    "\n",
    "- **Brownian Motion**  \n",
    "  - Simulate multiple paths of **standard Brownian motion**; check increment distribution & mean/variance.  \n",
    "  - Investigate **Geometric Brownian Motion** by simulating multiple stock-price paths. Compare Euler–Maruyama vs. exponential discretization.  \n",
    "  - Explore the **Reflection Principle** numerically.\n",
    "\n",
    "- **Variance Reduction: Antithetic Variables**  \n",
    "  - Implement a Monte Carlo estimator for $\\mathbb{E}[X]$, $X\\sim \\mathcal{N}(0,1)$ using antithetic pairs. Compare variance vs. independent sampling.  \n",
    "  - Modify $\\pi$-estimation code to see how quickly it converges with vs. without antithetic.\n",
    "\n",
    "- **Moment Control**  \n",
    "  - Generate normal samples with a specific mean & variance; verify the match.  \n",
    "  - Attempt to adjust skewness & kurtosis for a sample; discuss limitations.  \n",
    "  - Integrate moment-controlled samples into a basic Monte Carlo simulation and observe differences.\n",
    "\n",
    "- **Stochastic Modeling in Finance**  \n",
    "  - Compare a simple **Black–Scholes** formula for a European call vs. a Monte Carlo estimate.  \n",
    "  - Investigate how changing **volatility** $(\\sigma)$ affects the price under Black–Scholes vs. Monte Carlo.  \n",
    "  - Use the **monte_carlo_var** function to estimate 99% VaR and interpret the result."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
